{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed23fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30466449",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "> Core module of SALA, built to process actiwatch data for a single individual. Prepares actiwatch style data exported in a CSV from Philips Actiware watches and produces additional analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a4c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from astral import LocationInfo, sun\n",
    "\n",
    "import glob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti \n",
    "def firstAndLastLight(data, threshold_list, resamp=False):\n",
    "    ''' firstAndLastLight(data, threshold_list, resamp=False) applies all thresholds in the list to each unique person-day in the data, finding the first and last times as well as total times light intensity is above those thresholds for any non-zero number.  A 0 threshold is a request to calc amount of time spent at 5 lux and under.  Time resampling of the data is done if resamp is of the form [func name,'time'], such as [np.mean,'5T'] or [np.max,'15T'].'''\n",
    "    ids = data.UID.unique()\n",
    "    firstlight = []\n",
    "    lastlight = []\n",
    "    min2fl = []\n",
    "    min2ll = []\n",
    "    whoswatch = []\n",
    "    watchperiod = []\n",
    "    thresholds = []\n",
    "    datelist = []\n",
    "    grouplist = []\n",
    "    totalact=[]\n",
    "    tabvlight=[]\n",
    "    tabvlightAM=[]\n",
    "    tluxmin = []\n",
    "    tluxminAM = []\n",
    "\n",
    "    for uid in ids:\n",
    "            these_rows = (data.UID == uid) & (data['Interval Status'].isin(['ACTIVE','REST'])) & np.logical_not(data['Off-Wrist Status'])\n",
    "            \n",
    "            assert (these_rows.sum() > 0),\"ISSUE: \"+uid+\" has no ACTIVE rows\"\n",
    "                \n",
    "                \n",
    "            daysofdata = set( data[ these_rows ].index.date )\n",
    "            \n",
    "            if 'Group' in data.columns:\n",
    "                group = data[data.UID == uid].iloc[0,:][\"Group\"]\n",
    "            elif 'Season' in data.columns:\n",
    "                group = data[data.UID == uid].iloc[0,:][\"Season\"]\n",
    "            else:\n",
    "                print(\"ISSUE: Potentially no group variable?\")\n",
    "                raise ValueError\n",
    "                \n",
    "            for a_day in daysofdata:\n",
    "                nextday = a_day + pd.tseries.offsets.Day()\n",
    "                nextday = nextday.date().isoformat()\n",
    "                thisday = a_day.isoformat()\n",
    "                daylight = data[these_rows][thisday + ' 04:00:00' : nextday + ' 03:59:00']['White Light']\n",
    "                if resamp: # resample if the function argument is set\n",
    "                    daylight = daylight.resample(resamp[1]).apply(resamp[0]) \n",
    "                \n",
    "                # watch update period for todays data\n",
    "                dperiod = daylight.index.to_series().diff().min() \n",
    "                dpmult = dperiod/pd.Timedelta('1 min') # multiplier to get lux-minutes later\n",
    "                \n",
    "                lxmin =  dpmult * daylight.sum()\n",
    "                lxminAM = dpmult * daylight[:thisday + ' 12:00'].sum()\n",
    "                \n",
    "                for a_thresh in threshold_list:                                  \n",
    "                    thresholds.append(a_thresh)\n",
    "                    if a_thresh == 0 :\n",
    "                        abovethresh = daylight.index[ daylight < 5] # 0 theshold is a request to calculate under 5 lux\n",
    "                        abovethreshAM = daylight[:thisday + ' 12:00'].index[ daylight[:thisday + ' 12:00'] < 5]\n",
    "                    else:\n",
    "                        abovethresh = daylight.index[ daylight > a_thresh]\n",
    "                        abovethreshAM = daylight[:thisday + ' 12:00'].index[ daylight[:thisday + ' 12:00'] > a_thresh]         \n",
    "                    tabvlight.append( dperiod * len(abovethresh))\n",
    "                    tabvlightAM.append( dperiod * len(abovethreshAM))\n",
    "                    tluxmin.append( lxmin )\n",
    "                    tluxminAM.append( lxminAM )\n",
    "                    watchperiod.append(dperiod)\n",
    "                    datelist.append(a_day)\n",
    "                    grouplist.append(group)\n",
    "                    try:\n",
    "                        timelight = abovethresh[-1] # last time is above threshold\n",
    "                        mins4am = (timelight.time().hour - 4) * 60 + timelight.time().minute\n",
    "                        if mins4am < 0: # if after midnight, then value above is negative\n",
    "                            mins4am += 24 * 60 # fix by adding 24 hours (in minutes) to it\n",
    "                    except IndexError: # there is no above threshold level all day long\n",
    "                        timelight = np.nan\n",
    "                        mins4am = np.nan\n",
    "                    lastlight.append(timelight)\n",
    "                    min2ll.append(mins4am)\n",
    "                    try:\n",
    "                        timelight = abovethresh[0] # first time is above threshold\n",
    "                        mins4am = (timelight.time().hour - 4) * 60 + timelight.time().minute\n",
    "                        if mins4am < 0: # if after midnight, then value above is negative\n",
    "                            mins4am += 24 * 60 # fix by adding 24 hours (in minutes) to it\n",
    "                    except IndexError: # there is no above threshold level all day long\n",
    "                        timelight = np.nan\n",
    "                        mins4am = np.nan\n",
    "                    firstlight.append(timelight)\n",
    "                    min2fl.append(mins4am)\n",
    "                    whoswatch.append(uid)\n",
    "    return pd.DataFrame( {'UID': whoswatch, 'Date': datelist, 'Threshold': thresholds,\n",
    "                          'Last Light': lastlight, 'Mins to LL from 4AM': min2ll,\n",
    "                          'First Light': firstlight, 'Mins to FL from 4AM': min2fl,\n",
    "                          'Time above threshold': tabvlight, 'Time above threshold AM': tabvlightAM,\n",
    "                          'Minutes above threshold': [ el.total_seconds()/60.0 for el in tabvlight],\n",
    "                          'Minutes above threshold AM': [ el.total_seconds()/60.0 for el in tabvlightAM],\n",
    "                          'Lux minutes': tluxmin, 'Lux minutes AM': tluxminAM,\n",
    "                          'Group': grouplist,\n",
    "                          'Watch period': watchperiod \n",
    "                         } )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066abebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_actiwatch_data(path,uidprefix=''):\n",
    "     \n",
    "    if path[-1]!='/':    # make sure path has a trailing slash\n",
    "        path = path + '/'        \n",
    "    files = glob.glob(path+'*.csv') # gets all .csv filenames in directory \n",
    "    if not files: # let us know if there's no .csv files in path!\n",
    "        print('Oops! No csv files in ' + path)\n",
    "        raise OSError\n",
    "    else:\n",
    "        print('Found {} csv files in {}. Pass #1, raw data'.format(len(files),path)) \n",
    "        for _ in range(len(files)):\n",
    "            sys.stdout.write('.')            \n",
    "        sys.stdout.write('\\n')\n",
    "\n",
    "    frames = [] # list of data frames we will get from processing the files\n",
    "    for afile in files:\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "        with open(afile,'r') as f:\n",
    "            # we need to skip any previous analysis that's at the top of the \n",
    "            # file and get to the raw data below it\n",
    "            while True:\n",
    "                currentFilePosition = f.tell()\n",
    "                line = f.readline()\n",
    "                if line == '': # empty line read if EOF\n",
    "                    print('EOF without retrieving raw data: ' + afile)\n",
    "                    break # get out of this loop so we can go on to next file\n",
    "                cells = line.split(',') # comma seperated values (CSV)            \n",
    "                columns = tuple(filter( None, [el.strip().strip('\\\"') for el in cells])) #need tuple because in python3 filter is evaluated in lazy fasion\n",
    "                # DEBUG print len(columns),': ', columns\n",
    "                # the raw data has a 12 element long header line:\n",
    "                # Line , Date , Time , Off-wrist status , ....\n",
    "                if ( (len(columns)==12) and (columns[0] == 'Line') ):\n",
    "                    break\n",
    "                    \n",
    "            \n",
    "            if line == '': #empty line read if EOF\n",
    "                continue # go on to the next file\n",
    "                \n",
    "            # move the file pointer back to the beginning of the header line \n",
    "            # so we can read it in as a header for the DataFrame          \n",
    "            f.seek(currentFilePosition) \n",
    "            \n",
    "            # generate unique identifier for this individual based on filename\n",
    "            # assumes filename has format: \n",
    "            # /path/to/file/UID_Month_Date_Year_Time_*.csv \n",
    "            UID = uidprefix + afile.split('/')[-1].split('_')[0]\n",
    "\n",
    "            # grab the data, ignore the first column which just has line numbers\n",
    "            # stuff the two Date/Time columns into a single Date variable \n",
    "            fileData = pd.read_csv(f, index_col=False, usecols=columns[1:],\n",
    "                                       parse_dates={'DateTime': [0,1]})\n",
    "            fileData['UID'] = UID\n",
    "            \n",
    "            frames.append(fileData)\n",
    "            \n",
    "    rawWatchData = pd.concat(frames) # make one big dataframe  \n",
    "    rawWatchData.index = rawWatchData['DateTime']\n",
    "    del rawWatchData['DateTime']\n",
    "#%%\n",
    "    print('\\nPass #2, data summary') \n",
    "    for _ in range(len(files)):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write('\\n')\n",
    "\n",
    "    frames = [] # list of data frames we will get from processing the files\n",
    "    for afile in files:\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "        with open(afile,'r') as f:\n",
    "            # we need to skip to the summary statistics\n",
    "            while True:\n",
    "                summaryFilePosition = f.tell()\n",
    "                line = f.readline()\n",
    "                if line == '': #empty line read if EOF\n",
    "                    print('EOF without retrieving summary data: ' + afile)\n",
    "                    break # get out of this loop so we can go on to next file\n",
    "                cells = line.split(',') # comma seperated values (CSV)            \n",
    "                columns = tuple(filter( None, [el.strip().strip('\\\"') for el in cells])) #need tuple because in python3 filter is evaluated in lazy fasion\n",
    "                # print len(columns), columns[0]\n",
    "                # the raw data has a 35 element long header line:\n",
    "                # Interval Type , Interval #, Start Date, ....\n",
    "                if ( (len(columns)==35) and (columns[0] == 'Interval Type') ):\n",
    "                    break\n",
    "            \n",
    "            if line == '': #empty line read if EOF\n",
    "                continue # go on to the next file\n",
    "                \n",
    "            # advance to find out how many lines the summary includes\n",
    "            # since we don't care about excluded intervals and they \n",
    "            # also don't have a full set of columns, we stop there\n",
    "            nlines = 0\n",
    "            toskip = [1] # we skip the line after the header, it has units\n",
    "            while True:\n",
    "                line = f.readline()\n",
    "                if line == '': #empty line read if EOF\n",
    "                    print('EOF without retrieving summary data: ' + afile)\n",
    "                    break # get out of this loop so we can go on to next file\n",
    "                cells = line.split(',') # comma seperated values (CSV)            \n",
    "                columns = tuple(filter( None, [el.strip().strip('\\\"') for el in cells])) #need tuple because in python3 filter is evaluated in lazy fasion\n",
    "                nlines += 1\n",
    "                \n",
    "                if columns:\n",
    "                    if columns[0].find('Summary'):\n",
    "                        toskip.append(nlines)\n",
    "                    \n",
    "                    if columns[0] == 'EXCLUDED':\n",
    "                        break\n",
    "            \n",
    "            if line == '': #empty line read if EOF\n",
    "                continue # go on to the next file\n",
    "                \n",
    "            # move the file pointer back to the beginning of the header line \n",
    "            # so we can read it in as a header for the DataFrame          \n",
    "            f.seek(summaryFilePosition) \n",
    "            \n",
    "            # generate unique identifier for this individual based on filename\n",
    "            # assumes filename has format: \n",
    "            # /path/to/file/UID_Month_Date_Year_Time_*.csv \n",
    "            UID = uidprefix + afile.split('/')[-1].split('_')[0]\n",
    "\n",
    "            # grab the data, ignore the first column which just has line numbers\n",
    "            # stuff the two Date/Time columns into a single Date variable \n",
    "            fileData = pd.read_csv(f, index_col=False, skiprows=toskip,\n",
    "                                       nrows=nlines, skip_blank_lines=True)\n",
    "            fileData['UID'] = UID\n",
    "            \n",
    "            frames.append(fileData)\n",
    "    \n",
    "    if frames:        \n",
    "        summaryWatchData = pd.concat(frames)\n",
    "    else:\n",
    "        summaryWatchData = None\n",
    "    #%%        \n",
    "            \n",
    "    return (rawWatchData, summaryWatchData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SALAFrame:\n",
    "    \"\"\"\n",
    "    DataFrame-like storage for actiwatch data loaded either from a directory of csv files\n",
    "    or an existing SALA or dataframe object. \n",
    "    \n",
    "    \n",
    "        Attributes\n",
    "        ----------\n",
    "        data: pd.DataFrame or None\n",
    "            Initialized as None, but can be set as a dataframe, which is expected to contain\n",
    "            light and sleep information consistent with SALA formatting. It should only be \n",
    "            pre-set to an existing dataframe when trying to migrate existing data to a SALA\n",
    "            object. \n",
    "        \n",
    "        directory: dictionary or None\n",
    "            Dictionary style pairing of grouping names serving as keys (e.g. baseline,\n",
    "            intervention), with corresponding values as relative file paths storing csv\n",
    "            files to be read as data. \n",
    "            \n",
    "        timezone: str\n",
    "            Single timezone specified for all data within the object. A list of \n",
    "            valid timezones can be obtained from pytz.all_timezones. Note that it is impossible\n",
    "            for different timezones to be present (all data must be converted to a single timezone)\n",
    "\n",
    "        latitude: float\n",
    "            Latitude position for sunrise/sunset calculations. \n",
    "\n",
    "        longitude: float\n",
    "            Longitude position for sunrise/sunset calculations.\n",
    "\n",
    "        Methods\n",
    "        -------\n",
    "        init(data=None, directory=None, timezone=None, latitude=None, longitude=None)\n",
    "            Initialization with a pre-processed SALA-eqsue dataframe or raw data and file details\n",
    "            for loading and processing data.\n",
    "\n",
    "        get_raw_data_from_key(key, directory, grouping='Group')\n",
    "            Loads and combines all raw data from multiple csv files within a specified file source \n",
    "            based on a given key. Key indicates a grouping of multiple csvs. \n",
    "            \n",
    "        get_raw_data(directory, grouping='Group')\n",
    "            Loads and combines all raw data from multiple csv files for all keys within\n",
    "            a directory for a given directory of file sources. \n",
    "\n",
    "        export(data)\n",
    "            Exports the data within a SALA object to a parquet file format. \n",
    "\n",
    "        process_data(raw_data, thresholds)\n",
    "            Handles unprocessed combined raw data outputting first and last light times, \n",
    "            and group identifiers for all specified light thresholds.\n",
    "\n",
    "        sun_timings()\n",
    "            Calculates sunset and sunrise timing information for currently stored SALA\n",
    "            data, based on the timezone info within the stored data. \n",
    "            \n",
    "        do_everything()\n",
    "            TO ADD AFTER TESTING OTHER NEW FUNCTIONS. \n",
    "            \n",
    "        process_sleep_data\n",
    "            Processes sleep data for existing timing data, generating a summary dataframe\n",
    "            based on the number of sleep periods within the data. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latitude, longitude, timezone, data=None, directory = None):\n",
    "        \"\"\"\n",
    "        Initializes a SALA object either from existing parsed timing data, or from a directory\n",
    "        of csvs. Timezone information can be optionally included to allow for sunset, sunrise \n",
    "        data to be added.\n",
    "\n",
    "        #### Parameters\n",
    "\n",
    "            timezone: str \n",
    "                A valid timezone (a list of timezones can be obtained from pytz.all_timezones).\n",
    "            \n",
    "            latitude: float \n",
    "                Latitude position for sunrise/sunset calculations. Northern latitudes\n",
    "                should be positive values.\n",
    "                \n",
    "            longitude: float \n",
    "                Longitude position for sunrise/sunset calculations. Eastern longitudes\n",
    "                should be positive values.\n",
    "                \n",
    "            data: pd.DataFrame (optional)\n",
    "                If not None, data should be a pre-processed SALA-format dataframe, expected to contain \n",
    "                details on light and sleep information. \n",
    "            \n",
    "            directory: dictionary (optional)\n",
    "                Dictionary of valid folder names to load actiwatch data from.\n",
    "                Folders should have .csv files in them.\n",
    "        \"\"\"\n",
    "        self._data = data\n",
    "        self._directory = directory\n",
    "        self._timezone = timezone\n",
    "        self._latitude = latitude\n",
    "        self._longitude = longitude\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        \"\"\"Getter method for data.\"\"\"\n",
    "        return self._data\n",
    "    \n",
    "    @data.setter\n",
    "    def data(self, value):\n",
    "        \"\"\"Setter method for data.\"\"\"\n",
    "        if type(value) != pd.DataFrame:\n",
    "            raise TypeError(\"Error: Data must be of type pd.DataFrame\")\n",
    "        self._data = value\n",
    "    \n",
    "    @property\n",
    "    def directory(self):\n",
    "        \"\"\"Getter method for directory.\"\"\"\n",
    "        return self._directory\n",
    "    \n",
    "    @directory.setter\n",
    "    def directory(self, value):\n",
    "        \"\"\"Setter method for directory.\"\"\"\n",
    "        if type(value) != str:\n",
    "            raise TypeError(\"Error: directory must be a valid string\")\n",
    "        self._directory = value\n",
    "        \n",
    "    @property\n",
    "    def timezone(self):\n",
    "        \"\"\"Getter method for timezone.\"\"\"\n",
    "        return self._timezone\n",
    "    \n",
    "    @directory.setter\n",
    "    def timezone(self, value):\n",
    "        \"\"\"Setter method for timezone.\"\"\"\n",
    "        if type(value) != str:\n",
    "            raise TypeError(\"Error: timezone must be a valid string\")\n",
    "        self._timezone = value\n",
    "        \n",
    "    @property\n",
    "    def latitude(self):\n",
    "        \"\"\"Getter method for latitude.\"\"\"\n",
    "        return self._latitude\n",
    "    \n",
    "    @directory.setter\n",
    "    def latitude(self, value):\n",
    "        \"\"\"Setter method for latitude.\"\"\"\n",
    "        if not isinstance(value, (int, float, complex)):\n",
    "            raise TypeError(\"Error: latitude must be a numeric\")\n",
    "        self._latitude = value\n",
    "    \n",
    "    @property\n",
    "    def longitude(self):\n",
    "        \"\"\"Getter method for longitude.\"\"\"\n",
    "        return self._longitude\n",
    "    \n",
    "    @longitude.setter\n",
    "    def longitude(self, value):\n",
    "        \"\"\"Setter method for longitude.\"\"\"\n",
    "        if not isinstance(value, (int, float, complex)):\n",
    "            raise TypeError(\"Error: longitude must be a numeric\")\n",
    "        self._longitude = value\n",
    "        \n",
    "    def get_raw_data_from_key(self, key, directory = None, grouping = 'Group'):\n",
    "        \"\"\"Loads and combines raw actiwatch data from any csv files found in\n",
    "           the specified directory matching a particular key within the directory.\n",
    "\n",
    "            #### Parameters\n",
    "\n",
    "            key: str\n",
    "\n",
    "                The key to load actiwatch data from (for example, \"v1\").\n",
    "                \n",
    "            directory: dict\n",
    "\n",
    "                Dictionary of valid folders to load actiwatch data from.\n",
    "                Folders should have .csv files in them. If no dictionary\n",
    "                is provided, it uses the one initialized as part of the SALA\n",
    "                object.\n",
    "                \n",
    "            grouping: str\n",
    "\n",
    "                Name of the generated column for specifying groupings, where\n",
    "                the values will be the name of the key given. Default = 'Group'.\n",
    "                \n",
    "            #### Returns\n",
    "\n",
    "            All of the raw unprocessed data within the directory matching a specified key.\n",
    "\n",
    "    \"\"\"\n",
    "        if directory is None and self._directory is None:\n",
    "            raise ValueError(\"Error: a valid source of data must be provided.\")\n",
    "        if directory is not None:\n",
    "            self._directory = directory\n",
    "        raw_data = load_actiwatch_data(self.directory[key], uidprefix = key)[0]\n",
    "        raw_data[grouping] = key\n",
    "        return raw_data\n",
    "    \n",
    "    def get_raw_data(self, outfile, directory = None, grouping = 'Group', export = True):\n",
    "        \"\"\"Loads and combines raw actiwatch data from any csv files found in\n",
    "           the specified directory for all keys within the directory.\n",
    "\n",
    "            #### Parameters\n",
    "          \n",
    "            outfile: str\n",
    "            \n",
    "                Directory to save to. (e.g. ../SALA/example_output/)\n",
    "          \n",
    "            directory: dict\n",
    "\n",
    "                Dictionary of valid folders to load actiwatch data from.\n",
    "                Folders should have .csv files in them. If no dictionary\n",
    "                is provided, it uses the one initialized as part of the SALA\n",
    "                object.\n",
    "                \n",
    "            grouping: str\n",
    "\n",
    "                Name of the generated column for specifying groupings, where\n",
    "                the values will be the name of the key given. Default = 'Group'.\n",
    "                \n",
    "            export: bool\n",
    "            \n",
    "                Whether or not to export combined raw data to a parquet file saved in the designated\n",
    "                outfile location. \n",
    "                \n",
    "            #### Returns\n",
    "\n",
    "            All of the raw unprocessed data within the directory for all keys as a single\n",
    "            dataframe.\n",
    "\n",
    "    \"\"\"\n",
    "        if directory is None and self._directory is None:\n",
    "            raise ValueError(\"Error: a valid source of data must be provided.\")\n",
    "        if directory is not None:\n",
    "            self._directory = directory\n",
    "        raw_results = (\n",
    "            Parallel(n_jobs=len(self._directory))(delayed(self.get_raw_data_from_key)(key, self._directory) for key in self._directory.keys())\n",
    "                   )\n",
    "        # save data to parquet file\n",
    "        all_data = pd.concat(raw_results)\n",
    "        \n",
    "        if export: \n",
    "            all_data.to_parquet(outfile + \"raw.parquet\", engine = 'fastparquet',\n",
    "                                   compression = \"gzip\")\n",
    "        \n",
    "        return all_data\n",
    "    \n",
    "    def export(self, outfile, data=None):\n",
    "        \"\"\"\n",
    "        Exports existing timing data to a parquet format.\n",
    "        \n",
    "        #### Parameters\n",
    "            outfile: str\n",
    "\n",
    "                Directory to save to. (e.g. ../SALA/example_output/)\n",
    "            data: pd.DataFrame\n",
    "\n",
    "            Desired dataframe for exporting. \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.data is None and data is None:\n",
    "            raise Exception(\"Error: no timing data available to export.\")\n",
    "        if data is None:\n",
    "            data = self.data\n",
    "        # putting date information in a parquet valid format\n",
    "        data[\"Date\"] = data[\"Date\"].values.astype(\"datetime64[s]\")\n",
    "        data.to_parquet(f\"{outfile}timing.parquet\", \n",
    "                               engine = \"fastparquet\", compression=\"gzip\")\n",
    "    \n",
    "    \n",
    "    def process_data(self,\n",
    "                     raw_data, \n",
    "                     thresholds):\n",
    "        \"\"\"Handles unprocessed combined raw data outputting first and last light times, \n",
    "            and group identifiers for all specified light thresholds.\n",
    "\n",
    "        #### Parameters\n",
    "        \n",
    "        raw_data: pd.DataFrame\n",
    "            \n",
    "            Combined dataframe of all raw data from desired directory. This can be\n",
    "            accomplished by using the get_raw_data function within the SALA class. \n",
    "\n",
    "        thresholds: list\n",
    "\n",
    "            List of light thresholds for the watch data.\n",
    "\n",
    "        #### Returns\n",
    "            \n",
    "            Processed timing data in a dataframe format, with specific identifier columns based\n",
    "            on weekday and weekend/holiday groupings. \n",
    "        \"\"\"\n",
    "        timing_results = (Parallel(n_jobs=len(thresholds))\n",
    "        (delayed(firstAndLastLight)(raw_data, threshold) for threshold in thresholds)\n",
    "                         )\n",
    "        timing_data = pd.concat(timing_results)\n",
    "\n",
    "        # loading federal holidays to classify dates as weekend/holiday\n",
    "        cal = calendar()\n",
    "        holidays = (\n",
    "        cal.holidays(start = timing_data.Date.min(), end = timing_data.Date.max())\n",
    "    )\n",
    "        # retrieve day number (e.g. 0) from date index\n",
    "        timing_data[\"DayofWeek\"] = pd.DatetimeIndex(timing_data[\"Date\"]).dayofweek\n",
    "        days = [\"Mon\", \"Tues\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "        day_type = [\"Weekday\",\"Weekday\",\"Weekday\",\n",
    "                \"Weekday\",\"Weekday\",\"Weekend/Holiday\",\"Weekend/Holiday\"]\n",
    "\n",
    "        # result should be a combination of Group identifier and the day of the week (e.g. Mon)\n",
    "        timing_data[\"GroupDayofWeek\"] = (timing_data[\"Group\"] + np.array(days)[timing_data[\"DayofWeek\"]])\n",
    "\n",
    "        is_holiday = pd.to_datetime(timing_data[\"Date\"]).isin(holidays)\n",
    "        weekends = (timing_data[\"Group\"] + \"Weekend/Holiday\")\n",
    "\n",
    "         # result should be a combination of Group identifier and day type (e.g. Weekday)\n",
    "        day_types = (timing_data[\"Group\"] + np.array(day_type)[timing_data[\"DayofWeek\"]])                               \n",
    "\n",
    "        timing_data[\"GroupDayType\"] = day_types.where(~is_holiday).combine_first(weekends.where(is_holiday))\n",
    "        timing_data[\"Weekend/Holiday\"] = ((timing_data[\"DayofWeek\"] > 4) | is_holiday)\n",
    "\n",
    "        self._data = timing_data\n",
    "        timing_data[\"Watch period\"] = pd.to_timedelta(timing_data[\"Watch period\"])\n",
    "            \n",
    "        return timing_data\n",
    "    \n",
    "    def sun_timings(self):\n",
    "        \"\"\"Calculates sunrise and sunset timing information for data present in the\n",
    "        SALA object.\n",
    "\n",
    "        #### Returns\n",
    "\n",
    "            Modified timing data with sunrise and sunset calculations\n",
    "        \"\"\"\n",
    "        \n",
    "        if self._timezone is None or self._latitude is None or self._longitude is None:\n",
    "            raise ValueError(\"Error: Missing timezone, latitude, or longitude info.\")\n",
    "        \n",
    "        # add location info for calculating astral data\n",
    "        city = LocationInfo(\"location\", \"region\", self._timezone, self._latitude, self._longitude)\n",
    "        self._data[\"Sunrise\"] = self._data[\"Date\"].apply( lambda x: sun.sunrise(city.observer,\n",
    "                                                                           x,\n",
    "                                                                           tzinfo = city.tzinfo))\n",
    "        self._data[\"Sunset\"] = self._data[\"Date\"].apply( lambda x: sun.sunset(city.observer,\n",
    "                                                                         x,\n",
    "                                                                         tzinfo = city.tzinfo))\n",
    "        return self._data\n",
    "    \n",
    "    \n",
    "    def do_everything(self, outfile, thresholds, directory = None, grouping = \"Group\", export = True):\n",
    "        \"\"\"Handles the full SALA pipeline (excluding sleep period analysis), from processing and combining raw data\n",
    "        to parsing and calculating processed data with sunrise and sunset information. First loads and compiles \n",
    "        all existing raw data for every key within the given directory. Then processes all raw data, calculating\n",
    "        additional information for all specified light thresholds. Also adds sunrise and sunset information. \n",
    "        \n",
    "        #### Parameters\n",
    "        \n",
    "        outfile: str\n",
    "            \n",
    "                Directory to save to. (e.g. ../SALA/example_output/)\n",
    "                \n",
    "        thresholds: list\n",
    "\n",
    "            List of light thresholds for the watch data.\n",
    "            \n",
    "        directory: dict\n",
    "\n",
    "            Dictionary of valid folders to load actiwatch data from.\n",
    "            Folders should have .csv files in them. If no dictionary\n",
    "            is provided, it uses the one initialized as part of the SALA\n",
    "            object.\n",
    "                \n",
    "        grouping: str\n",
    "\n",
    "            Name of the generated column for specifying groupings, where\n",
    "            the values will be the name of the key given. Default = 'Group'.\n",
    "            \n",
    "        export: bool\n",
    "            \n",
    "            Whether or not to export processed timing data to a parquet file saved in the designated\n",
    "            outfile location. \n",
    "            \n",
    "        #### Returns\n",
    "            \n",
    "            Processed timing data in a dataframe format, with specific identifier columns based\n",
    "            on weekday and weekend/holiday groupings, and included sunrise and sunset calculations. \n",
    "        \"\"\"\n",
    "        if directory == None:\n",
    "            directory = self.directory\n",
    "            \n",
    "        raw_data = self.get_raw_data(outfile, directory, grouping)\n",
    "        data = self.process_data(raw_data, thresholds)\n",
    "        self.sun_timings()\n",
    "        \n",
    "        if export:\n",
    "            self.export(data = self.data, outfile = outfile)\n",
    "            \n",
    "        return self._data\n",
    "        \n",
    "    \n",
    "    def process_sleep(self, raw_data, sleep_split = \"18:00\", num_sleeps = 3):\n",
    "        \"\"\"Processes sleep data for existing timing data.\n",
    "\n",
    "        #### Parameters\n",
    "        \n",
    "        raw_data: pd.DataFrame\n",
    "\n",
    "            Combined dataframe of all raw data from desired directory. This can be\n",
    "            accomplished by using the get_raw_data function within the SALA class. \n",
    "            \n",
    "        sleep_split: str\n",
    "\n",
    "            Time to split the sleep day. Default is \"18:00\", which is 6:00PM.\n",
    "            \n",
    "        num_sleeps: int\n",
    "\n",
    "            Cutoff for number of sleeps to display in first resulting frame.\n",
    "            Default = 3, frame will store days with 3+ sleep instances\n",
    "\n",
    "        #### Returns\n",
    "\n",
    "            short_frame: pd.DataFrame\n",
    "\n",
    "                Onset, offset, and duration for sleep periods on days with\n",
    "                more than num_sleeps number of sleep periods\n",
    "                \n",
    "            timing_data: pd.DataFrame\n",
    "\n",
    "                Modified timing data with included sleep information\n",
    "\n",
    "        \"\"\"\n",
    "        sleepers = []\n",
    "        sleep_onsets = []\n",
    "        sleep_offsets = []\n",
    "        sleep_durations = []\n",
    "        sleep_onsetMSLMs = []\n",
    "        sleep_offsetMSLMs = []\n",
    "        \n",
    "        timing_data = self._data\n",
    "        for arow in timing_data.itertuples():\n",
    "            UID = arow.UID\n",
    "            DT = pd.to_datetime(arow.Date)\n",
    "            TM = pd.to_datetime(DT + pd.Timedelta(\"1 day\"))\n",
    "            today = DT.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            nextday = TM.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            # taking raw timing data entry and splitting a \"sleep day\" at 6pm\n",
    "            # under the assumption that people do not end their days that early\n",
    "            day_split = raw_data.query(\"UID == @UID\").loc[today +\" \" + sleep_split:nextday + \" 18:00\"]\n",
    "\n",
    "            # REST-S = watch thinks user is asleep\n",
    "            asleep = day_split[ day_split[\"Interval Status\"] == \"REST-S\"].copy()\n",
    "\n",
    "            # there may be more than one sleep period in a given day's data\n",
    "            # new sleep period = when there is more than 1 hour between successive REST-S entries\n",
    "            sleep_periods = []\n",
    "            per = 0\n",
    "            count = 0\n",
    "\n",
    "            try:\n",
    "                lt = asleep.index[0]\n",
    "                for time in asleep.index:\n",
    "                    # allow up to 1 hour of being awake in the middle of the night\n",
    "                    if (time - lt > pd.Timedelta(\"1 hour\")):\n",
    "                        per += 1\n",
    "                    lt = time\n",
    "                    sleep_periods.append(per)\n",
    "                asleep[\"Sleep period\"] = sleep_periods\n",
    "            except IndexError:\n",
    "                asleep[\"Sleep period\"] = [pd.to_datetime(0)]\n",
    "\n",
    "            try:\n",
    "            # calc sleep onsets/offsets/duration for each period of sleep in a person-day of data\n",
    "                sleeps = asleep.reset_index().groupby(\"Sleep period\").apply( lambda x: pd.DataFrame({\n",
    "                         \"Sleep onset\": [x.DateTime.min()],\n",
    "                         \"Sleep offset\": [x.DateTime.max()],\n",
    "                         \"Sleep duration\": [x.DateTime.max() - x.DateTime.min()]\n",
    "                         }, index = x.DateTime.dt.normalize() ))\n",
    "            # if the value is = 0 -> np.int64 (not a DateTime)\n",
    "            except AttributeError:\n",
    "                sleeps = asleep.reset_index().groupby(\"Sleep period\").apply( lambda x: pd.DataFrame({\n",
    "                 \"Sleep onset\": [pd.to_datetime(DT)],\n",
    "                 \"Sleep offset\": [pd.to_datetime(DT)],\n",
    "                 \"Sleep duration\": [pd.to_timedelta(x.DateTime.max() - x.DateTime.min())]\n",
    "                 }))\n",
    "            sleeps = sleeps.drop_duplicates().sort_values(by=\"Sleep duration\", ascending = False)\n",
    "            onset = sleeps.iloc[0]['Sleep onset']\n",
    "            offset = sleeps.iloc[0]['Sleep offset']\n",
    "            dur =  sleeps.iloc[0]['Sleep duration']\n",
    "\n",
    "            # if onset is actually a datetime\n",
    "            if not isinstance(onset, np.int64):\n",
    "                onMSLM = (onset - DT).total_seconds() / 60.0\n",
    "\n",
    "            # if offset is actually a datetime\n",
    "            if not isinstance(offset, np.int64):\n",
    "                offMSLM = np.maximum((offset - TM).total_seconds() / 60.0, 0.0)\n",
    "\n",
    "            sleep_onsets.append(onset)\n",
    "            sleep_offsets.append(offset)\n",
    "            sleep_durations.append(dur)\n",
    "            sleep_onsetMSLMs.append(onMSLM)\n",
    "            sleep_offsetMSLMs.append(offMSLM)\n",
    "            sleep_count = sleeps.shape[0]\n",
    "\n",
    "            # adding to short_frame\n",
    "            if sleep_count >= num_sleeps:\n",
    "                sleeps['UID'] = UID\n",
    "                sleeps['DT'] = DT\n",
    "                sleeps.reset_index(drop = True).set_index(['UID','DT'])\n",
    "                sleepers.append(sleeps)\n",
    "        short_frame = (\n",
    "                       pd.concat(sleepers).reset_index().drop('DateTime',axis=1)\n",
    "                       .set_index(['UID','DT']).drop_duplicates()\n",
    "                       )\n",
    "        timing_data[\"Sleep onset\"] = sleep_onsets\n",
    "        timing_data[\"Sleep offset\"] = sleep_offsets\n",
    "        timing_data[\"Sleep duration\"] = sleep_durations\n",
    "        timing_data[\"Sleep onset MSLM\"] = sleep_onsetMSLMs\n",
    "        timing_data[\"Sleep offset MSLM\"] = sleep_offsetMSLMs\n",
    "        \n",
    "        self._data = timing_data\n",
    "        \n",
    "        return short_frame, timing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4d958",
   "metadata": {},
   "source": [
    "## Creating SALA Objects\n",
    "\n",
    "SALA objects can be created by using the initialization method provided. This method requires location specific information and either existing data or a data source directory:\n",
    "\n",
    "#### Latitude, Longitude, Timezone\n",
    "\n",
    "These location specific information pieces are necessary in generating accurate sunrise and sunset timings.\n",
    "\n",
    "\n",
    "#### Data\n",
    "\n",
    "This should consist of a processed dataframe in SALA-style, with corresponding columns such as \n",
    "\"First Light\", \"Date\", \"Lux Minutes\", etc. Data should be entered as a variable in cases where existing data missing sunrise or sunset data is available or for immediate use with SALA-style plots. \n",
    "\n",
    "#### Directory\n",
    "\n",
    "In most cases, it is preferred to have a directory entered. A directory should be in dictionary style, where keys denote file groupings (e.g. baseline versus intervention) and the values denote relative file paths/folders to find csv stored data in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb62229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SALAFrame.__init__\" class=\"doc_header\"><code>SALAFrame.__init__</code><a href=\"__main__.py#L65\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SALAFrame.__init__</code>(**`latitude`**, **`longitude`**, **`timezone`**, **`data`**=*`None`*, **`directory`**=*`None`*)\n",
       "\n",
       "Initializes a SALA object either from existing parsed timing data, or from a directory\n",
       "of csvs. Timezone information can be optionally included to allow for sunset, sunrise \n",
       "data to be added.\n",
       "\n",
       "#### Parameters\n",
       "\n",
       "    timezone: str \n",
       "        A valid timezone (a list of timezones can be obtained from pytz.all_timezones).\n",
       "    \n",
       "    latitude: float \n",
       "        Latitude position for sunrise/sunset calculations. Northern latitudes\n",
       "        should be positive values.\n",
       "        \n",
       "    longitude: float \n",
       "        Longitude position for sunrise/sunset calculations. Eastern longitudes\n",
       "        should be positive values.\n",
       "        \n",
       "    data: pd.DataFrame (optional)\n",
       "        If not None, data should be a pre-processed SALA-format dataframe, expected to contain \n",
       "        details on light and sleep information. \n",
       "    \n",
       "    directory: dictionary (optional)\n",
       "        Dictionary of valid folder names to load actiwatch data from.\n",
       "        Folders should have .csv files in them."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SALAFrame.__init__, title_level = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe8850",
   "metadata": {},
   "source": [
    "SALA objects can be initialized in one of two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = {\n",
    "    'base_': 'data/v1',\n",
    "    'follow_up_': 'data/v3'\n",
    "}\n",
    "timezone = \"America/Los_Angeles\"\n",
    "latitude = 47.65\n",
    "longitude = -122.30\n",
    "\n",
    "sala_from_directory = SALAFrame(latitude, longitude, timezone, directory = directory)\n",
    "\n",
    "data = pd.read_parquet(\"example_output/timing.parquet\")\n",
    "sala_from_data = SALAFrame(latitude, longitude, timezone, data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46362861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "sala = sala_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2e85a",
   "metadata": {},
   "source": [
    "## Loading Actiwatch Data and Raw Data Manipulation\n",
    "\n",
    "Actiwatch data should be loaded in a directory-style setup with key value pairings. This is intended to provide a generally flexible method for group labeling within the data for easier grouped searching and analysis.\n",
    "\n",
    "#### Keys\n",
    "\n",
    "Keys should be indicative of the group name and are used in generating UIDs. The in-documentation example below uses base_ and follow_up_ as its keys. \n",
    "\n",
    "#### Values\n",
    "\n",
    "Corresponding Values should be relative file paths to find csv data to be loaded for a respective group. The example data uses csvs within two folders \"data/v1\" and \"data/v3\" which correspond to the keys \"base_\" and \"follow_up_\" respectively. Note that the trailing part of the folder path (after the final /) is appended to the UID. The remaining part of the UID is build using the filename within the subfolder. \n",
    "\n",
    "\n",
    "Following this structure, an example file titled \"user1234\" in \"data/v1\" would generate a UID of \"base_v1\\user1234\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b3beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SALAFrame.get_raw_data_from_key\" class=\"doc_header\"><code>SALAFrame.get_raw_data_from_key</code><a href=\"__main__.py#L158\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SALAFrame.get_raw_data_from_key</code>(**`key`**, **`directory`**=*`None`*, **`grouping`**=*`'Group'`*)\n",
       "\n",
       "Loads and combines raw actiwatch data from any csv files found in\n",
       "the specified directory matching a particular key within the directory.\n",
       "\n",
       " #### Parameters\n",
       "\n",
       " key: str\n",
       "\n",
       "     The key to load actiwatch data from (for example, \"v1\").\n",
       "     \n",
       " directory: dict\n",
       "\n",
       "     Dictionary of valid folders to load actiwatch data from.\n",
       "     Folders should have .csv files in them. If no dictionary\n",
       "     is provided, it uses the one initialized as part of the SALA\n",
       "     object.\n",
       "     \n",
       " grouping: str\n",
       "\n",
       "     Name of the generated column for specifying groupings, where\n",
       "     the values will be the name of the key given. Default = 'Group'.\n",
       "     \n",
       " #### Returns\n",
       "\n",
       " All of the raw unprocessed data within the directory matching a specified key."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SALAFrame.get_raw_data_from_key, title_level = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8524a8f7",
   "metadata": {},
   "source": [
    "### Loading Data for a Single Key \n",
    "\n",
    "Raw data for a particular key within the directory can be gathered by giving this function a key and a directory to load data from. If no directory is given, the function will automatically use the directory specified when creating a SALA object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6273938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 csv files in data/v1/. Pass #1, raw data\n",
      ".\n",
      ".\n",
      "Pass #2, data summary\n",
      ".\n",
      ".EOF without retrieving summary data: data/v1\\user1234_v1sample.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Off-Wrist Status</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Marker</th>\n",
       "      <th>White Light</th>\n",
       "      <th>Red Light</th>\n",
       "      <th>Green Light</th>\n",
       "      <th>Blue Light</th>\n",
       "      <th>Sleep/Wake</th>\n",
       "      <th>Interval Status</th>\n",
       "      <th>UID</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-25 12:31:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.09</td>\n",
       "      <td>28.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25 12:31:30</th>\n",
       "      <td>0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.15</td>\n",
       "      <td>159.0</td>\n",
       "      <td>59.9</td>\n",
       "      <td>65.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25 12:32:00</th>\n",
       "      <td>0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.03</td>\n",
       "      <td>113.0</td>\n",
       "      <td>49.8</td>\n",
       "      <td>50.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25 12:32:30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.95</td>\n",
       "      <td>365.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25 12:33:00</th>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.82</td>\n",
       "      <td>264.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Off-Wrist Status  Activity  Marker  White Light  \\\n",
       "DateTime                                                               \n",
       "2018-06-25 12:31:00                 0       0.0     0.0        37.09   \n",
       "2018-06-25 12:31:30                 0     170.0     0.0       156.15   \n",
       "2018-06-25 12:32:00                 0     194.0     0.0       149.03   \n",
       "2018-06-25 12:32:30                 0       0.0     0.0       473.95   \n",
       "2018-06-25 12:33:00                 0      62.0     0.0       317.82   \n",
       "\n",
       "                     Red Light  Green Light  Blue Light  Sleep/Wake  \\\n",
       "DateTime                                                              \n",
       "2018-06-25 12:31:00       28.4         15.5        14.5         1.0   \n",
       "2018-06-25 12:31:30      159.0         59.9        65.3         1.0   \n",
       "2018-06-25 12:32:00      113.0         49.8        50.6         1.0   \n",
       "2018-06-25 12:32:30      365.0        161.0       161.0         1.0   \n",
       "2018-06-25 12:33:00      264.0        112.0       115.0         1.0   \n",
       "\n",
       "                    Interval Status               UID  Group  \n",
       "DateTime                                                      \n",
       "2018-06-25 12:31:00          ACTIVE  base_v1\\user1234  base_  \n",
       "2018-06-25 12:31:30          ACTIVE  base_v1\\user1234  base_  \n",
       "2018-06-25 12:32:00          ACTIVE  base_v1\\user1234  base_  \n",
       "2018-06-25 12:32:30          ACTIVE  base_v1\\user1234  base_  \n",
       "2018-06-25 12:33:00          ACTIVE  base_v1\\user1234  base_  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = sala.get_raw_data_from_key(\"base_\")\n",
    "raw_data.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1620323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SALAFrame.get_raw_data\" class=\"doc_header\"><code>SALAFrame.get_raw_data</code><a href=\"__main__.py#L193\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SALAFrame.get_raw_data</code>(**`outfile`**, **`directory`**=*`None`*, **`grouping`**=*`'Group'`*, **`export`**=*`True`*)\n",
       "\n",
       "Loads and combines raw actiwatch data from any csv files found in\n",
       "the specified directory for all keys within the directory.\n",
       "\n",
       " #### Parameters\n",
       "\n",
       " outfile: str\n",
       " \n",
       "     Directory to save to. (e.g. ../SALA/example_output/)\n",
       "\n",
       " directory: dict\n",
       "\n",
       "     Dictionary of valid folders to load actiwatch data from.\n",
       "     Folders should have .csv files in them. If no dictionary\n",
       "     is provided, it uses the one initialized as part of the SALA\n",
       "     object.\n",
       "     \n",
       " grouping: str\n",
       "\n",
       "     Name of the generated column for specifying groupings, where\n",
       "     the values will be the name of the key given. Default = 'Group'.\n",
       "     \n",
       " export: bool\n",
       " \n",
       "     Whether or not to export combined raw data to a parquet file saved in the designated\n",
       "     outfile location. \n",
       "     \n",
       " #### Returns\n",
       "\n",
       " All of the raw unprocessed data within the directory for all keys as a single\n",
       " dataframe."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SALAFrame.get_raw_data, title_level = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6895e2",
   "metadata": {},
   "source": [
    "### Loading Data for All Keys\n",
    "\n",
    "Raw data for all keys can similarly be loaded by providing an outfile to save the generated file to. Saving is controlled via a boolean command. A directory to load data from is also necessary. If no directory is given, the function will automatically use the directory specified when creating a SALA object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec598a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Off-Wrist Status</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Marker</th>\n",
       "      <th>White Light</th>\n",
       "      <th>Red Light</th>\n",
       "      <th>Green Light</th>\n",
       "      <th>Blue Light</th>\n",
       "      <th>Sleep/Wake</th>\n",
       "      <th>Interval Status</th>\n",
       "      <th>UID</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-06-25 12:31:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.09</td>\n",
       "      <td>28.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25 12:31:30</th>\n",
       "      <td>0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.15</td>\n",
       "      <td>159.0</td>\n",
       "      <td>59.9</td>\n",
       "      <td>65.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25 12:32:00</th>\n",
       "      <td>0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.03</td>\n",
       "      <td>113.0</td>\n",
       "      <td>49.8</td>\n",
       "      <td>50.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25 12:32:30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473.95</td>\n",
       "      <td>365.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-25 12:33:00</th>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.82</td>\n",
       "      <td>264.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Off-Wrist Status  Activity  Marker  White Light  \\\n",
       "DateTime                                                               \n",
       "2018-06-25 12:31:00                 0       0.0     0.0        37.09   \n",
       "2018-06-25 12:31:30                 0     170.0     0.0       156.15   \n",
       "2018-06-25 12:32:00                 0     194.0     0.0       149.03   \n",
       "2018-06-25 12:32:30                 0       0.0     0.0       473.95   \n",
       "2018-06-25 12:33:00                 0      62.0     0.0       317.82   \n",
       "\n",
       "                     Red Light  Green Light  Blue Light  Sleep/Wake  \\\n",
       "DateTime                                                              \n",
       "2018-06-25 12:31:00       28.4         15.5        14.5         1.0   \n",
       "2018-06-25 12:31:30      159.0         59.9        65.3         1.0   \n",
       "2018-06-25 12:32:00      113.0         49.8        50.6         1.0   \n",
       "2018-06-25 12:32:30      365.0        161.0       161.0         1.0   \n",
       "2018-06-25 12:33:00      264.0        112.0       115.0         1.0   \n",
       "\n",
       "                    Interval Status               UID  Group  \n",
       "DateTime                                                      \n",
       "2018-06-25 12:31:00          ACTIVE  base_v1\\user1234  base_  \n",
       "2018-06-25 12:31:30          ACTIVE  base_v1\\user1234  base_  \n",
       "2018-06-25 12:32:00          ACTIVE  base_v1\\user1234  base_  \n",
       "2018-06-25 12:32:30          ACTIVE  base_v1\\user1234  base_  \n",
       "2018-06-25 12:33:00          ACTIVE  base_v1\\user1234  base_  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfile = \"../SALA/example_output/\"\n",
    "all_raw_data = sala.get_raw_data(outfile, export=True)\n",
    "all_raw_data.dropna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8adad",
   "metadata": {},
   "source": [
    "## Exporting Data\n",
    "\n",
    "SALA provides its own export function for taking existing SALA data and saving it to a parquet file. To save existing SALA data an outfile location must be provided. By default SALA exports the data stored within the object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905eaa0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SALAFrame.export\" class=\"doc_header\"><code>SALAFrame.export</code><a href=\"__main__.py#L242\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SALAFrame.export</code>(**`outfile`**, **`data`**=*`None`*)\n",
       "\n",
       "Exports existing timing data to a parquet format.\n",
       "\n",
       "#### Parameters\n",
       "    outfile: str\n",
       "\n",
       "        Directory to save to. (e.g. ../SALA/example_output/)\n",
       "    data: pd.DataFrame\n",
       "\n",
       "    Desired dataframe for exporting. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SALAFrame.export, title_level = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc493c",
   "metadata": {},
   "source": [
    "## Processing Data\n",
    "\n",
    "The main functionality of SALA's is data processing. SALA's processing functions handle unprocessed combined raw data to outputt first and last light times, and group identifiers for specified light thresholds. SALA also supports adding sunrise and sunset data based on latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa07439c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SALAFrame.process_data\" class=\"doc_header\"><code>SALAFrame.process_data</code><a href=\"__main__.py#L265\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SALAFrame.process_data</code>(**`raw_data`**, **`thresholds`**)\n",
       "\n",
       "Handles unprocessed combined raw data outputting first and last light times, \n",
       "    and group identifiers for all specified light thresholds.\n",
       "\n",
       "#### Parameters\n",
       "\n",
       "raw_data: pd.DataFrame\n",
       "    \n",
       "    Combined dataframe of all raw data from desired directory. This can be\n",
       "    accomplished by using the get_raw_data function within the SALA class. \n",
       "\n",
       "thresholds: list\n",
       "\n",
       "    List of light thresholds for the watch data.\n",
       "\n",
       "#### Returns\n",
       "    \n",
       "    Processed timing data in a dataframe format, with specific identifier columns based\n",
       "    on weekday and weekend/holiday groupings. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SALAFrame.process_data, title_level = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ab48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [[5], [10], [50], [100], [500], [1000]] \n",
    "outfile = \"../SALA/example_output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331d297",
   "metadata": {},
   "source": [
    "At this stage, any extra processing functions can be directly applied to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07598a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def remove_first_day(data):\n",
    "    \"\"\"An example function that removes data\n",
    "    from the first day of recording. Typically the first\n",
    "    day has no light data for these watches (represented\n",
    "    as 'NaT')\n",
    "    \"\"\"\n",
    "    return data[(data[\"Last Light\"].apply(np.isnat) == False)\n",
    "               & (data[\"Date\"] != data[\"Date\"].min())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22883de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sala.data = sala.process_data(all_raw_data, thresholds)\n",
    "sala.data = remove_first_day(sala.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81044998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Last Light</th>\n",
       "      <th>Mins to LL from 4AM</th>\n",
       "      <th>First Light</th>\n",
       "      <th>Mins to FL from 4AM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>2018-06-30</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-06-30 22:22:00</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>2018-06-30 07:56:30</td>\n",
       "      <td>236.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-03 23:31:00</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>2018-07-03 07:00:30</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-06-27 22:57:00</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>2018-06-27 09:12:30</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>2018-07-07</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-08 00:01:30</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>2018-07-07 06:54:30</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_v1\\user1234</td>\n",
       "      <td>2018-07-08</td>\n",
       "      <td>5</td>\n",
       "      <td>2018-07-08 20:45:30</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>2018-07-08 06:45:00</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                UID        Date  Threshold          Last Light  \\\n",
       "0  base_v1\\user1234  2018-06-30          5 2018-06-30 22:22:00   \n",
       "1  base_v1\\user1234  2018-07-03          5 2018-07-03 23:31:00   \n",
       "2  base_v1\\user1234  2018-06-27          5 2018-06-27 22:57:00   \n",
       "3  base_v1\\user1234  2018-07-07          5 2018-07-08 00:01:30   \n",
       "4  base_v1\\user1234  2018-07-08          5 2018-07-08 20:45:30   \n",
       "\n",
       "   Mins to LL from 4AM         First Light  Mins to FL from 4AM  \n",
       "0               1102.0 2018-06-30 07:56:30                236.0  \n",
       "1               1171.0 2018-07-03 07:00:30                180.0  \n",
       "2               1137.0 2018-06-27 09:12:30                312.0  \n",
       "3               1201.0 2018-07-07 06:54:30                174.0  \n",
       "4               1005.0 2018-07-08 06:45:00                165.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sala.data.iloc[:,:7].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7662c8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time above threshold</th>\n",
       "      <th>Time above threshold AM</th>\n",
       "      <th>Minutes above threshold</th>\n",
       "      <th>Minutes above threshold AM</th>\n",
       "      <th>Lux minutes</th>\n",
       "      <th>Lux minutes AM</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 days 10:04:00</td>\n",
       "      <td>0 days 03:26:30</td>\n",
       "      <td>604.0</td>\n",
       "      <td>206.5</td>\n",
       "      <td>779254.835</td>\n",
       "      <td>473764.040</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 12:47:30</td>\n",
       "      <td>0 days 03:37:30</td>\n",
       "      <td>767.5</td>\n",
       "      <td>217.5</td>\n",
       "      <td>377968.040</td>\n",
       "      <td>143815.500</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 days 10:25:00</td>\n",
       "      <td>0 days 02:23:00</td>\n",
       "      <td>625.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>640912.350</td>\n",
       "      <td>247699.580</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 days 11:45:30</td>\n",
       "      <td>0 days 04:37:30</td>\n",
       "      <td>705.5</td>\n",
       "      <td>277.5</td>\n",
       "      <td>814059.620</td>\n",
       "      <td>355668.225</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 days 11:46:30</td>\n",
       "      <td>0 days 04:39:30</td>\n",
       "      <td>706.5</td>\n",
       "      <td>279.5</td>\n",
       "      <td>478718.375</td>\n",
       "      <td>154556.710</td>\n",
       "      <td>base_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Time above threshold Time above threshold AM  Minutes above threshold  \\\n",
       "0      0 days 10:04:00         0 days 03:26:30                    604.0   \n",
       "1      0 days 12:47:30         0 days 03:37:30                    767.5   \n",
       "2      0 days 10:25:00         0 days 02:23:00                    625.0   \n",
       "3      0 days 11:45:30         0 days 04:37:30                    705.5   \n",
       "4      0 days 11:46:30         0 days 04:39:30                    706.5   \n",
       "\n",
       "   Minutes above threshold AM  Lux minutes  Lux minutes AM  Group  \n",
       "0                       206.5   779254.835      473764.040  base_  \n",
       "1                       217.5   377968.040      143815.500  base_  \n",
       "2                       143.0   640912.350      247699.580  base_  \n",
       "3                       277.5   814059.620      355668.225  base_  \n",
       "4                       279.5   478718.375      154556.710  base_  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sala.data.iloc[:,7:14].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe3dbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Watch period</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>GroupDayofWeek</th>\n",
       "      <th>GroupDayType</th>\n",
       "      <th>Weekend/Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 days 00:00:30</td>\n",
       "      <td>5</td>\n",
       "      <td>base_Sat</td>\n",
       "      <td>base_Weekend/Holiday</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 00:00:30</td>\n",
       "      <td>1</td>\n",
       "      <td>base_Tues</td>\n",
       "      <td>base_Weekday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 days 00:00:30</td>\n",
       "      <td>2</td>\n",
       "      <td>base_Wed</td>\n",
       "      <td>base_Weekday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0 days 00:00:30</td>\n",
       "      <td>5</td>\n",
       "      <td>base_Sat</td>\n",
       "      <td>base_Weekend/Holiday</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 days 00:00:30</td>\n",
       "      <td>6</td>\n",
       "      <td>base_Sun</td>\n",
       "      <td>base_Weekend/Holiday</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Watch period  DayofWeek GroupDayofWeek          GroupDayType  \\\n",
       "0 0 days 00:00:30          5       base_Sat  base_Weekend/Holiday   \n",
       "1 0 days 00:00:30          1      base_Tues          base_Weekday   \n",
       "2 0 days 00:00:30          2       base_Wed          base_Weekday   \n",
       "3 0 days 00:00:30          5       base_Sat  base_Weekend/Holiday   \n",
       "4 0 days 00:00:30          6       base_Sun  base_Weekend/Holiday   \n",
       "\n",
       "   Weekend/Holiday  \n",
       "0             True  \n",
       "1            False  \n",
       "2            False  \n",
       "3             True  \n",
       "4             True  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sala.data.iloc[:,14:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e83a0",
   "metadata": {},
   "source": [
    "## Setting Sunset and Sunrise\n",
    "\n",
    "SALA provides the ability to add sunrise and sunset information to processed data. To do so, the specific location (longitude and latitude) is required. To get correct sunrise and sunset times relative to a specific location, a timezone is also required. These fields are necessary when creating a SALA object and do not specifically need to be re-entered when calling SALA's sun timing function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39206e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SALAFrame.sun_timings\" class=\"doc_header\"><code>SALAFrame.sun_timings</code><a href=\"__main__.py#L320\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SALAFrame.sun_timings</code>()\n",
       "\n",
       "Calculates sunrise and sunset timing information for data present in the\n",
       "SALA object.\n",
       "\n",
       "#### Returns\n",
       "\n",
       "    Modified timing data with sunrise and sunset calculations"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SALAFrame.sun_timings, title_level = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e324d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-30 05:15:10.009843-07:00</td>\n",
       "      <td>2018-06-30 21:10:28.189308-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-03 05:17:02.116743-07:00</td>\n",
       "      <td>2018-07-03 21:09:39.386344-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-06-27 05:13:37.265731-07:00</td>\n",
       "      <td>2018-06-27 21:10:53.349244-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-07 05:19:59.495724-07:00</td>\n",
       "      <td>2018-07-07 21:07:57.880755-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-08 05:20:48.480661-07:00</td>\n",
       "      <td>2018-07-08 21:07:26.089296-07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Sunrise                           Sunset\n",
       "0 2018-06-30 05:15:10.009843-07:00 2018-06-30 21:10:28.189308-07:00\n",
       "1 2018-07-03 05:17:02.116743-07:00 2018-07-03 21:09:39.386344-07:00\n",
       "2 2018-06-27 05:13:37.265731-07:00 2018-06-27 21:10:53.349244-07:00\n",
       "3 2018-07-07 05:19:59.495724-07:00 2018-07-07 21:07:57.880755-07:00\n",
       "4 2018-07-08 05:20:48.480661-07:00 2018-07-08 21:07:26.089296-07:00"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sala.data = sala.sun_timings()\n",
    "sala.data[[\"Sunrise\", \"Sunset\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344e21e2",
   "metadata": {},
   "source": [
    "## Complete Processing\n",
    "\n",
    "SALA additionally has a do-it-all function that handles the entire process from loading data from a directory up to adding sunrise and sunset information. It additionally defaults to exporting the information. It requires an outfile for potential saving, and light thresholds to work with. If a directory is not provided, it will use the directory present within the SALA object that was provided upon object creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efa5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SALAFrame.do_everything\" class=\"doc_header\"><code>SALAFrame.do_everything</code><a href=\"__main__.py#L343\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SALAFrame.do_everything</code>(**`outfile`**, **`thresholds`**, **`directory`**=*`None`*, **`grouping`**=*`'Group'`*, **`export`**=*`True`*)\n",
       "\n",
       "Handles the full SALA pipeline (excluding sleep period analysis), from processing and combining raw data\n",
       "to parsing and calculating processed data with sunrise and sunset information. First loads and compiles \n",
       "all existing raw data for every key within the given directory. Then processes all raw data, calculating\n",
       "additional information for all specified light thresholds. Also adds sunrise and sunset information. \n",
       "\n",
       "#### Parameters\n",
       "\n",
       "outfile: str\n",
       "    \n",
       "        Directory to save to. (e.g. ../SALA/example_output/)\n",
       "        \n",
       "thresholds: list\n",
       "\n",
       "    List of light thresholds for the watch data.\n",
       "    \n",
       "directory: dict\n",
       "\n",
       "    Dictionary of valid folders to load actiwatch data from.\n",
       "    Folders should have .csv files in them. If no dictionary\n",
       "    is provided, it uses the one initialized as part of the SALA\n",
       "    object.\n",
       "        \n",
       "grouping: str\n",
       "\n",
       "    Name of the generated column for specifying groupings, where\n",
       "    the values will be the name of the key given. Default = 'Group'.\n",
       "    \n",
       "export: bool\n",
       "    \n",
       "    Whether or not to export processed timing data to a parquet file saved in the designated\n",
       "    outfile location. \n",
       "    \n",
       "#### Returns\n",
       "    \n",
       "    Processed timing data in a dataframe format, with specific identifier columns based\n",
       "    on weekday and weekend/holiday groupings, and included sunrise and sunset calculations. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SALAFrame.do_everything, title_level = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d76eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [[5], [10], [50], [100], [500], [1000]] \n",
    "outfile = \"../SALA/example_output/\"\n",
    "results = sala.do_everything(outfile, thresholds, export=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbeabae",
   "metadata": {},
   "source": [
    "## Additional Sleep Information\n",
    "\n",
    "Adding sleep information to the processed data is also possible. The below function adds sleep data, allowing a \"sleep day\" to be split at a customizable time. The outputs of the function are:\n",
    "\n",
    "1. short_frame: \n",
    "    a separate dataframe meant to be a quick way of visually subsetting and viewing bi/polyphasic instances. \n",
    "    This frame defaults to storing occurances of at least 3 sleep periods within a \"sleep day\", but can be modified.\n",
    "\n",
    "2. timing_data:\n",
    "    modifies stored data to have sleep period information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede3b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"SALAFrame.process_sleep\" class=\"doc_header\"><code>SALAFrame.process_sleep</code><a href=\"__main__.py#L394\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>SALAFrame.process_sleep</code>(**`raw_data`**, **`sleep_split`**=*`'18:00'`*, **`num_sleeps`**=*`3`*)\n",
       "\n",
       "Processes sleep data for existing timing data.\n",
       "\n",
       "#### Parameters\n",
       "\n",
       "raw_data: pd.DataFrame\n",
       "\n",
       "    Combined dataframe of all raw data from desired directory. This can be\n",
       "    accomplished by using the get_raw_data function within the SALA class. \n",
       "    \n",
       "sleep_split: str\n",
       "\n",
       "    Time to split the sleep day. Default is \"18:00\", which is 6:00PM.\n",
       "    \n",
       "num_sleeps: int\n",
       "\n",
       "    Cutoff for number of sleeps to display in first resulting frame.\n",
       "    Default = 3, frame will store days with 3+ sleep instances\n",
       "\n",
       "#### Returns\n",
       "\n",
       "    short_frame: pd.DataFrame\n",
       "\n",
       "        Onset, offset, and duration for sleep periods on days with\n",
       "        more than num_sleeps number of sleep periods\n",
       "        \n",
       "    timing_data: pd.DataFrame\n",
       "\n",
       "        Modified timing data with included sleep information"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(SALAFrame.process_sleep, title_level = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a635f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_frame, timing_data = sala.process_sleep(all_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb91cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Sleep period</th>\n",
       "      <th>Sleep onset</th>\n",
       "      <th>Sleep offset</th>\n",
       "      <th>Sleep duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UID</th>\n",
       "      <th>DT</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">base_v1\\user1234</th>\n",
       "      <th>2018-06-28</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-29 00:40:30</td>\n",
       "      <td>2018-06-29 06:41:00</td>\n",
       "      <td>0 days 06:00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-28</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-29 13:42:00</td>\n",
       "      <td>2018-06-29 15:23:30</td>\n",
       "      <td>0 days 01:41:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-28</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-06-29 08:50:30</td>\n",
       "      <td>2018-06-29 09:04:00</td>\n",
       "      <td>0 days 00:13:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">follow_up_v3\\user1234</th>\n",
       "      <th>2018-09-17</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-09-17 23:11:00</td>\n",
       "      <td>2018-09-18 06:29:30</td>\n",
       "      <td>0 days 07:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-17</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-09-18 16:11:00</td>\n",
       "      <td>2018-09-18 16:40:30</td>\n",
       "      <td>0 days 00:29:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Sleep period         Sleep onset  \\\n",
       "UID                   DT                                             \n",
       "base_v1\\user1234      2018-06-28             0 2018-06-29 00:40:30   \n",
       "                      2018-06-28             2 2018-06-29 13:42:00   \n",
       "                      2018-06-28             1 2018-06-29 08:50:30   \n",
       "follow_up_v3\\user1234 2018-09-17             0 2018-09-17 23:11:00   \n",
       "                      2018-09-17             2 2018-09-18 16:11:00   \n",
       "\n",
       "                                        Sleep offset  Sleep duration  \n",
       "UID                   DT                                              \n",
       "base_v1\\user1234      2018-06-28 2018-06-29 06:41:00 0 days 06:00:30  \n",
       "                      2018-06-28 2018-06-29 15:23:30 0 days 01:41:30  \n",
       "                      2018-06-28 2018-06-29 09:04:00 0 days 00:13:30  \n",
       "follow_up_v3\\user1234 2018-09-17 2018-09-18 06:29:30 0 days 07:18:30  \n",
       "                      2018-09-17 2018-09-18 16:40:30 0 days 00:29:30  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb73d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sleep onset</th>\n",
       "      <th>Sleep offset</th>\n",
       "      <th>Sleep duration</th>\n",
       "      <th>Sleep onset MSLM</th>\n",
       "      <th>Sleep offset MSLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-06-25 20:55:30</td>\n",
       "      <td>2018-06-26 06:51:00</td>\n",
       "      <td>0 days 09:55:30</td>\n",
       "      <td>1255.5</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-04 22:23:00</td>\n",
       "      <td>2018-07-05 06:36:00</td>\n",
       "      <td>0 days 08:13:00</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-05 23:27:00</td>\n",
       "      <td>2018-07-06 06:29:00</td>\n",
       "      <td>0 days 07:02:00</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-06-29 00:40:30</td>\n",
       "      <td>2018-06-29 06:41:00</td>\n",
       "      <td>0 days 06:00:30</td>\n",
       "      <td>1480.5</td>\n",
       "      <td>401.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-03 23:57:30</td>\n",
       "      <td>2018-07-04 06:14:00</td>\n",
       "      <td>0 days 06:16:30</td>\n",
       "      <td>1437.5</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sleep onset        Sleep offset  Sleep duration  Sleep onset MSLM  \\\n",
       "0 2018-06-25 20:55:30 2018-06-26 06:51:00 0 days 09:55:30            1255.5   \n",
       "1 2018-07-04 22:23:00 2018-07-05 06:36:00 0 days 08:13:00            1343.0   \n",
       "2 2018-07-05 23:27:00 2018-07-06 06:29:00 0 days 07:02:00            1407.0   \n",
       "3 2018-06-29 00:40:30 2018-06-29 06:41:00 0 days 06:00:30            1480.5   \n",
       "4 2018-07-03 23:57:30 2018-07-04 06:14:00 0 days 06:16:30            1437.5   \n",
       "\n",
       "   Sleep offset MSLM  \n",
       "0              411.0  \n",
       "1              396.0  \n",
       "2              389.0  \n",
       "3              401.0  \n",
       "4              374.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing_data[\n",
    "    [\"Sleep onset\", \"Sleep offset\",\n",
    "     \"Sleep duration\", \"Sleep onset MSLM\",\n",
    "     \"Sleep offset MSLM\"]\n",
    "    ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678e009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
